{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db2e24c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (1176, 48)\n",
      "Target shape: (1176,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "X_scaled = pd.read_csv('../data/processed/X_scaled.csv')\n",
    "y = pd.read_csv('../data/processed/y.csv')['outcome']\n",
    "\n",
    "print(f\"Loaded data shape: {X_scaled.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22072244",
   "metadata": {},
   "source": [
    "# 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a135e4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in y: 0\n",
      "Outcome distribution:\n",
      "outcome\n",
      "0.0    1017\n",
      "1.0     159\n",
      "Name: count, dtype: int64\n",
      "Outcome unique values: [0. 1.]\n",
      "\n",
      "Cleaned data shapes:\n",
      "X: (1176, 48), y: (1176,)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and clean data\n",
    "print(f\"Missing values in y: {y.isna().sum()}\")\n",
    "print(f\"Outcome distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Outcome unique values: {y.unique()}\")\n",
    "\n",
    "# Remove rows with missing outcomes from BOTH X and y\n",
    "mask = ~y.isna()\n",
    "X_scaled_clean = X_scaled[mask]\n",
    "y_clean = y[mask]\n",
    "\n",
    "print(f\"\\nCleaned data shapes:\")\n",
    "print(f\"X: {X_scaled_clean.shape}, y: {y_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc9c0c",
   "metadata": {},
   "source": [
    "# 2. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f69a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (940, 48)\n",
      "Test set: (236, 48)\n",
      "Train outcome distribution:\n",
      "outcome\n",
      "0.0    813\n",
      "1.0    127\n",
      "Name: count, dtype: int64\n",
      "Test outcome distribution:\n",
      "outcome\n",
      "0.0    204\n",
      "1.0     32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean)\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Train outcome distribution:\\n{pd.Series(y_train).value_counts()}\")\n",
    "print(f\"Test outcome distribution:\\n{pd.Series(y_test).value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8dfef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.8771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.93       204\n",
      "         1.0       0.60      0.28      0.38        32\n",
      "\n",
      "    accuracy                           0.88       236\n",
      "   macro avg       0.75      0.63      0.66       236\n",
      "weighted avg       0.86      0.88      0.86       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42) \n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911bb859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.8771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93       204\n",
      "         1.0       0.71      0.16      0.26        32\n",
      "\n",
      "    accuracy                           0.88       236\n",
      "   macro avg       0.80      0.57      0.59       236\n",
      "weighted avg       0.86      0.88      0.84       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806143e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.8729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.97      0.93       204\n",
      "         1.0       0.57      0.25      0.35        32\n",
      "\n",
      "    accuracy                           0.87       236\n",
      "   macro avg       0.73      0.61      0.64       236\n",
      "weighted avg       0.85      0.87      0.85       236\n",
      "\n",
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.8729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.97      0.93       204\n",
      "         1.0       0.57      0.25      0.35        32\n",
      "\n",
      "    accuracy                           0.87       236\n",
      "   macro avg       0.73      0.61      0.64       236\n",
      "weighted avg       0.85      0.87      0.85       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(y_train))\n",
    "print(f\"Number of classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae0d3ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammedsagare/Documents/Coding/ICU-Mortality-Prediction/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Results:\n",
      "Accuracy: 0.8856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       204\n",
      "         1.0       0.63      0.38      0.47        32\n",
      "\n",
      "    accuracy                           0.89       236\n",
      "   macro avg       0.77      0.67      0.70       236\n",
      "weighted avg       0.87      0.89      0.87       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "print(\"Training Neural Network...\")\n",
    "\n",
    "# two hidden layers with dropout to prevent overfitting\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "y_pred_nn = (nn_model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\nNeural Network Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nn):.4f}\")\n",
    "print(classification_report(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdedbd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "MODEL COMPARISON\n",
      "--------------------------------------------------\n",
      "Neural Network      : 0.8856\n",
      "Logistic Regression : 0.8771\n",
      "Random Forest       : 0.8771\n",
      "XGBoost             : 0.8729\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Logistic Regression': accuracy_score(y_test, y_pred_lr),\n",
    "    'Random Forest': accuracy_score(y_test, y_pred_rf),\n",
    "    'XGBoost': accuracy_score(y_test, y_pred_xgb),\n",
    "    'Neural Network': accuracy_score(y_test, y_pred_nn)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"-\"*50)\n",
    "for model, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{model:20s}: {acc:.4f}\")\n",
    "print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
